{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/CRM-jupyter/blob/main/CRM_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/CRM-hf\n",
        "%cd /content/CRM-hf\n",
        "\n",
        "!pip install -q gradio diffusers==0.24.0 einops==0.7.0 omegaconf rembg trimesh xatlas kiui open-clip-torch==2.7.0 pymeshlab\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab/nvdiffrast-0.3.1-py3-none-any.whl\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/CRM/resolve/main/ccm-diffusion.pth -d /content/models -o ccm-diffusion.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/CRM/resolve/main/pixel-diffusion.pth -d /content/models -o pixel-diffusion.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/CRM/resolve/main/CRM.pth -d /content/models -o CRM.pth\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "from PIL import Image\n",
        "import PIL\n",
        "from pipelines import TwoStagePipeline\n",
        "import rembg\n",
        "from typing import Any\n",
        "import json\n",
        "\n",
        "from model import CRM\n",
        "from inference import generate3d\n",
        "\n",
        "pipeline = None\n",
        "rembg_session = rembg.new_session()\n",
        "\n",
        "def expand_to_square(image, bg_color=(0, 0, 0, 0)):\n",
        "    # expand image to 1:1\n",
        "    width, height = image.size\n",
        "    if width == height:\n",
        "        return image\n",
        "    new_size = (max(width, height), max(width, height))\n",
        "    new_image = Image.new(\"RGBA\", new_size, bg_color)\n",
        "    paste_position = ((new_size[0] - width) // 2, (new_size[1] - height) // 2)\n",
        "    new_image.paste(image, paste_position)\n",
        "    return new_image\n",
        "\n",
        "def check_input_image(input_image):\n",
        "    if input_image is None:\n",
        "        print(\"No image uploaded!\")\n",
        "\n",
        "\n",
        "def remove_background(\n",
        "    image: PIL.Image.Image,\n",
        "    rembg_session: Any = None,\n",
        "    force: bool = False,\n",
        "    **rembg_kwargs,\n",
        ") -> PIL.Image.Image:\n",
        "    do_remove = True\n",
        "    if image.mode == \"RGBA\" and image.getextrema()[3][0] < 255:\n",
        "        # explain why current do not rm bg\n",
        "        print(\"alhpa channl not enpty, skip remove background, using alpha channel as mask\")\n",
        "        background = Image.new(\"RGBA\", image.size, (0, 0, 0, 0))\n",
        "        image = Image.alpha_composite(background, image)\n",
        "        do_remove = False\n",
        "    do_remove = do_remove or force\n",
        "    if do_remove:\n",
        "        image = rembg.remove(image, session=rembg_session, **rembg_kwargs)\n",
        "    return image\n",
        "\n",
        "def do_resize_content(original_image: Image, scale_rate):\n",
        "    # resize image content wile retain the original image size\n",
        "    if scale_rate != 1:\n",
        "        # Calculate the new size after rescaling\n",
        "        new_size = tuple(int(dim * scale_rate) for dim in original_image.size)\n",
        "        # Resize the image while maintaining the aspect ratio\n",
        "        resized_image = original_image.resize(new_size)\n",
        "        # Create a new image with the original size and black background\n",
        "        padded_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
        "        paste_position = ((original_image.width - resized_image.width) // 2, (original_image.height - resized_image.height) // 2)\n",
        "        padded_image.paste(resized_image, paste_position)\n",
        "        return padded_image\n",
        "    else:\n",
        "        return original_image\n",
        "\n",
        "def add_background(image, bg_color=(255, 255, 255)):\n",
        "    # given an RGBA image, alpha channel is used as mask to add background color\n",
        "    background = Image.new(\"RGBA\", image.size, bg_color)\n",
        "    return Image.alpha_composite(background, image)\n",
        "\n",
        "def preprocess_image(image, background_choice, foreground_ratio, backgroud_color):\n",
        "    \"\"\"\n",
        "    input image is a pil image in RGBA, return RGB image\n",
        "    \"\"\"\n",
        "    print(background_choice)\n",
        "    if background_choice == \"Alpha as mask\":\n",
        "        background = Image.new(\"RGBA\", image.size, (0, 0, 0, 0))\n",
        "        image = Image.alpha_composite(background, image)\n",
        "    else:\n",
        "        image = remove_background(image, rembg_session, force=True)\n",
        "    image = do_resize_content(image, foreground_ratio)\n",
        "    image = expand_to_square(image)\n",
        "    image = add_background(image, backgroud_color)\n",
        "    return image.convert(\"RGB\")\n",
        "\n",
        "def gen_image(input_image, seed, scale, step):\n",
        "    global pipeline, model\n",
        "    pipeline.set_seed(seed)\n",
        "    rt_dict = pipeline(input_image, scale=scale, step=step)\n",
        "    stage1_images = rt_dict[\"stage1_images\"]\n",
        "    stage2_images = rt_dict[\"stage2_images\"]\n",
        "    np_imgs = np.concatenate(stage1_images, 1)\n",
        "    np_xyzs = np.concatenate(stage2_images, 1)\n",
        "\n",
        "    glb_path = generate3d(model, np_imgs, np_xyzs, \"cuda:0\")\n",
        "    return Image.fromarray(np_imgs), Image.fromarray(np_xyzs), glb_path#, obj_path\n",
        "\n",
        "crm_path = \"/content/models/CRM.pth\"\n",
        "specs = json.load(open(\"configs/specs_objaverse_total.json\"))\n",
        "model = CRM(specs)\n",
        "model.load_state_dict(torch.load(crm_path, map_location=\"cpu\"), strict=False)\n",
        "model = model.to(\"cuda:0\")\n",
        "\n",
        "stage1_config = OmegaConf.load(\"configs/nf7_v3_SNR_rd_size_stroke.yaml\").config\n",
        "stage2_config = OmegaConf.load(\"configs/stage2-v2-snr.yaml\").config\n",
        "stage2_sampler_config = stage2_config.sampler\n",
        "stage1_sampler_config = stage1_config.sampler\n",
        "\n",
        "stage1_model_config = stage1_config.models\n",
        "stage2_model_config = stage2_config.models\n",
        "\n",
        "xyz_path = \"/content/models/ccm-diffusion.pth\"\n",
        "pixel_path = \"/content/models/pixel-diffusion.pth\"\n",
        "stage1_model_config.resume = pixel_path\n",
        "stage2_model_config.resume = xyz_path\n",
        "\n",
        "pipeline = TwoStagePipeline(\n",
        "    stage1_model_config,\n",
        "    stage2_model_config,\n",
        "    stage1_sampler_config,\n",
        "    stage2_sampler_config,\n",
        "    device=\"cuda:0\",\n",
        "    dtype=torch.float32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(\"/content/CRM-hf/examples/bulldog.webp\")\n",
        "processed_image = preprocess_image(image, \"Auto Remove background\", 1.0, \"#7F7F7F\")\n",
        "output_model = gen_image(processed_image, 1234, 5.5, 30)\n",
        "output_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
